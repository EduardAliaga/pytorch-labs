{"cells":[{"cell_type":"markdown","metadata":{"id":"bNgvzqC1IBjH"},"source":["# Recurrent Neural Networks\n","\n","## Lab credit\n","Created by [Santiago Pascual](https://scholar.google.es/citations?user=7cVOyh0AAAAJ&hl=ca) and [Xavier Giro-i-Nieto](https://imatge.upc.edu/web/people/xavier-giro) for the [Postgraduate course in artificial intelligence with deep learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) in [UPC School](https://www.talent.upc.edu/ing/) (2019).\n","\n","Updated by [Gerard I. G치llego](https://www.linkedin.com/in/gerard-gallego/) in 2021, and by [Javier Ferrando](https://www.linkedin.com/in/javierferrandomonsonis/) in 2022.\n"]},{"cell_type":"markdown","metadata":{"id":"PqBBz46awSAh"},"source":["# The Fault in Our Time\n","\n","This lab session introduces our beloved friends, the [recurrent neural networks (RNNs)](https://en.wikipedia.org/wiki/Recurrent_neural_network). Concretely, the topology we will be seeing is the Elman type, nowadays widely known plainly as RNN. Recurrent neural networks are the super cool queens of sequences: they know about order in sequences. As a quick test for how important sequential context is, and to prove that it is also very important for you... **CAN YOU TELL THE SIXTH DIGIT OF YOUR MOBILE PHONE NUMBER? WHAT PROCESS ARE YOU FOLLOWING TO RECALL IT?** Exactly, you went straight from the beginning of the full sequence, hence this is how important sequences are to us too :)\n","\n","As in the example before, we always work with sequences when using RNNs. In each batch of data, we have as many elements as the length of the sequence (seq_len), and each of these elements can contain multiple features (num_feats):\n","\n","<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/input_batch.png?raw=true\" class=\"center\" title=\"input batch\" width=\"300\"/>\n","</p><br>\n","\n","A fully connected layer is defined as:\n","\n","$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{b})$\n","\n","With \"only one\" (but super important) change we formulate the RNN:\n","\n","$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{W}\\boldsymbol{x}_t + \\boldsymbol{U}\\boldsymbol{h}_{t-1} + \\boldsymbol{b})$\n","\n","Exactly, we added the matrix $\\boldsymbol{U}$ which is a set of connections among all the neurons from the hidden layers to themselves (hence a feedback)!\n","\n","This looks like the following, which is typically unrolled in time to show both flows of data, feed-forward ($\\boldsymbol{W}$) + time ($\\boldsymbol{U}$):\n","\n","<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/one_layer_rnn.png?raw=true\" class=\"center\" title=\"one layer RNN\" width=\"300\"/>\n","</p><br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goGysyRAeML1"},"outputs":[],"source":["# Let's first import the typical stuff to play with deep nets\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.optim as optim\n","import matplotlib\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from timeit import default_timer as timer\n","\n","torch.manual_seed(1)\n","device = 'cpu'\n","if torch.cuda.is_available():\n","  device = 'cuda'\n","  torch.cuda.manual_seed_all(1)\n","#cada vez que vayamos infiriendo el state se ira actualizando\n"]},{"cell_type":"markdown","metadata":{"id":"e8YHdo2o0Ago"},"source":["### Exercise 1: Building a recurrent neural layer\n","\n","In the next cell, we will define our own unidirectional RNN layer. The class `MyUnidirectionalRNN` must make use of `nn.Linear` layers to make the feed-forward and time projections, and use the `nn.Parameter` class to build the biases. Please build the recurrent neural component with the addition of the recurrent connections.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1669627534508,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"ztfKN35deML3","outputId":"f5ba973b-1b63-4a21-894c-6007004ff3dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success! Output shape: 5 sequences, each of length 15, each token with 32 dims\n"]}],"source":["class MyUnidirectionalRNN(nn.Module):\n","\n","  def __init__(self, num_feats, rnn_size=128):\n","    super().__init__()\n","    self.rnn_size = rnn_size\n","\n","    # Definition of the RNN parameters with the use of Linear layers:\n","\n","    # Define the input activation matrix W\n","    self.W = nn.Linear(num_feats, rnn_size, bias=False)\n","\n","    # TODO: Define the hidden activation matrix U\n","    self.U = nn.Linear(rnn_size, rnn_size, bias=False)\n","    #quieres que tenga el tama침o interior al tama침o interior, es de ella a si misma, pr eso debe ser del mismo tama침o\n","\n","    # Define the bias\n","    self.b = nn.Parameter(torch.zeros(1, rnn_size))\n","\n","  def forward(self, x, state=None):\n","    # Assuming x is of shape [batch_size, seq_len, num_feats]\n","    xs = torch.chunk(x, x.shape[1], dim=1)\n","    hts = []\n","    if state is None:\n","      state = self.init_state(x.shape[0])\n","    ht = state\n","    for xt in xs:\n","      # turn x[t] into shape [batch_size, num_feats] to be projected\n","      xt = xt.squeeze(1)\n","      ct = self.W(xt)\n","      ct = ct + self.U(ht)\n","      ht = ct + self.b\n","      # give the temporal dimension back to h[t] to be cated\n","      hts.append(ht.unsqueeze(1))\n","    hts = torch.cat(hts, dim=1)\n","    return hts\n","\n","  def init_state(self, batch_size):\n","    return torch.zeros(batch_size, self.rnn_size)\n","\n","# To correctly assess the answer, we build an example RNN with 10 inputs and 32 neurons\n","rnn = MyUnidirectionalRNN(10, 32)\n","# Then we will forward some random sequences, each of length 15\n","xt = torch.randn(5, 15, 10)\n","# The returned tensor will be h[t]\n","ht = rnn(xt)\n","assert ht.shape[0] == 5 and ht.shape[1] == 15 and ht.shape[2] == 32, \\\n","'Something went wrong within the RNN :('\n","print('Success! Output shape: {} sequences, each of length {}, each '\\\n","      'token with {} dims'.format(ht.shape[0], ht.shape[1], ht.shape[2]))"]},{"cell_type":"markdown","metadata":{"id":"THnEZ6UmPAJU"},"source":["### But Why Would You Do That?\n","\n","Congratz on finishing your first RNN definition! Now you should understand a bit more on the intrinsics of our sequential friends. But why would you define your own RNN? We didn't even operate with a GPU. We didn't even consider that possibility. So in the real world, we use PyTorch's `nn.RNN`, which allows for building a **stack of RNN layers directly**. Let's see some examples:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669627555738,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"GR07CQtreML5","outputId":"30c83146-f962-4af2-ba6d-81fdb7f48f72"},"outputs":[{"name":"stdout","output_type":"stream","text":["RNN(10, 128)\n","Output h[t] tensor shape:  torch.Size([25, 5, 128])\n","Output state tensor shape:  torch.Size([1, 5, 128])\n"]}],"source":["# we will work with 10 input features\n","NUM_FEATS = 10\n","# and sequences of length 25\n","SEQ_LEN = 25\n","# and 5 samples per batch\n","BATCH_SIZE = 5 \n","# and 128 neurons\n","HIDDEN_SIZE = 128\n","\n","# The first RNN contains a single layer\n","rnn1 = nn.RNN(NUM_FEATS, HIDDEN_SIZE)\n","print(rnn1)\n","\n","# Now let's build a random input tensor to forward through it\n","xt = torch.randn(SEQ_LEN, BATCH_SIZE, NUM_FEATS)\n","ht, state = rnn1(xt)\n","print('Output h[t] tensor shape: ', ht.shape)\n","print('Output state tensor shape: ', state.shape)"]},{"cell_type":"markdown","metadata":{"id":"eg4c-TaLQ5Ag"},"source":["#### OK STOP IT HERE, We've got to talk\n","\n","Think about how many things are happening in the previous cell. First, we define some hyper-parameters to define the input tensor shape and the RNN size. Then, we build one RNN layer. Then, we build random data. Finally, we forward the random data, and what is returned? Why does the input tensor `x` have that shape? Why is the RNN returning 2 output values?\n","\n","**First answer:** The input data to an RNN can be shaped in 2 formats: `batch_first=True` and `batch_first=False`. As its name indicates, when it is `False`, the `batch_size` dimension is not the first but the second one. Then which is the first one? The `sequence_length`. If we do not specify anything, by default `batch_first=False`, so the tensor $\\boldsymbol{x}_t$ must have the dimensions: [`seq_len`, `batch_size`, `num_feats`]. We normally use `batch_first=True` to couple the RNN easily with other layers like the `nn.Linear` one.\n","\n","### Exercise 2\n","\n","Find the second answer on \"**Why is the RNN returning 2 output values?**\". Understand what is the `state` output and answer: \"**what does it contain?**\". Your source of knowledge is in the following URL, where the outputs description for the `RNN` module is given: https://pytorch.org/docs/stable/nn.html#torch.nn.RNN\n"]},{"cell_type":"markdown","metadata":{"id":"1wAY1wWTT3pR"},"source":["Now we can continue defining some more examples of RNN layers as promised before"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1669627864803,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"26DIhQw6eML6","outputId":"83102169-e539-4d93-b321-a59dce5379a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["RNN 2 layers >> ht.shape:  torch.Size([25, 5, 128])\n","RNN 2 layers >> state.shape:  torch.Size([2, 5, 128])\n","RNN 2 layers, batch_first >> ht.shape:  torch.Size([5, 25, 128])\n","RNN 2 layers, batch_first >> state.shape:  torch.Size([2, 5, 128])\n"]}],"source":["# 2 Layer RNN\n","rnn2 = nn.RNN(NUM_FEATS, HIDDEN_SIZE, num_layers=2)\n","ht, state = rnn2(xt)\n","print('RNN 2 layers >> ht.shape: ', ht.shape)\n","print('RNN 2 layers >> state.shape: ', state.shape)\n","\n","# Batch Size first RNN\n","xt_bf = torch.randn(BATCH_SIZE, SEQ_LEN, NUM_FEATS)\n","rnn3 = nn.RNN(NUM_FEATS, HIDDEN_SIZE, num_layers=2, batch_first=True)\n","ht, state = rnn3(xt_bf)\n","print('RNN 2 layers, batch_first >> ht.shape: ', ht.shape)\n","print('RNN 2 layers, batch_first >> state.shape: ', state.shape)"]},{"cell_type":"markdown","metadata":{"id":"aNGrWTyorkNg"},"source":["<p align=\"center\"><br>\n","<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/rnn/images/two_layers_rnn.png?raw=true\" class=\"center\" title=\"two layers RNN\" width=\"300\"/>\n","</p><br>"]},{"cell_type":"markdown","metadata":{"id":"cfRkpNiOUwxA"},"source":["### Exercise 3.1\n","Build a **bidirectional RNN with 3 layers** by completing the TODO in the code."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1669627990139,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"ee5ygWAFeML8","outputId":"f6fa338f-bab9-4ec1-ab84-81ca0c669260"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bidirectional RNN layer >> bi_ht.shape:  torch.Size([5, 25, 256])\n","Bidirectional RNN layer >> bi_state.shape:  torch.Size([6, 5, 128])\n"]}],"source":["# TODO: build the bidirectional RNN layer\n","bi_rnn = nn.RNN(NUM_FEATS, HIDDEN_SIZE, num_layers=3, batch_first=True, bidirectional=True)\n","\n","# forward xt_bf\n","bi_ht, bi_state = bi_rnn(xt_bf)\n","print('Bidirectional RNN layer >> bi_ht.shape: ', bi_ht.shape)\n","print('Bidirectional RNN layer >> bi_state.shape: ', bi_state.shape)"]},{"cell_type":"markdown","metadata":{"id":"fDE81Z2XKN2J"},"source":["### Exercise 3.2\n","What is the output $\\boldsymbol{h}_t$ shape and why?\n","\n","bi_ht=[batch size, seq_length, 2*hidden_size]\n","\n","### Exercise 3.3\n","What is the output `state` shape and why?.\n","bi_state=[2*hidden_layers, batch_size, hidden_size]"]},{"cell_type":"markdown","metadata":{"id":"HgKP_9eKTQcp"},"source":["### Hold The Gates! A Recurrent Re-Evolution\n","\n","You've surely heard about the `LSTM` or the `GRU`, two practically sibling recurrent models. Well those are the actual RNNs you will use in your everyday. Why? Because they:\n","1. Improve the memory capacity of the RNN.\n","2. Improve the gradient flow of vanilla RNNs thanks to the learnable gate mechanisms.\n","\n","An LSTM or GRU cell is a composition of different neurons working jointly, and the whole thing replaces a single RNN neuron. The RNN cell (with one $\\tanh$ neuron), the LSTM cell and the GRU cell are depicted in the following figure from [this article](https://www.google.com/url?sa=i&rct=j&q=&esrc=s&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwiMiPbfoPHlAhUQCxoKHW9qA04Qjhx6BAgBEAI&url=http%3A%2F%2Fdprogrammer.org%2Frnn-lstm-gru&psig=AOvVaw3mU76KRvFfY9WiOF4N12ex&ust=1574080203478260):\n","\n","![lstm](http://dprogrammer.org/wp-content/uploads/2019/04/RNN-vs-LSTM-vs-GRU-1200x361.png)\n","\n","Now check that out. In the case of the LSTM, we have **two signals flowing in time** apart from the feed-forward input per time-step: $\\boldsymbol{c}_t$ and $\\boldsymbol{h}_t$. The first one is called the cumulative cell state. It basically will add everything it is \"allowed to see\" from the input, and will forget portions of it. This is unbounded. On the other hand, the output cell state $\\boldsymbol{h}_t$ will be the final layer activation (what is allowed to come out of it). This is bounded [-1, 1]."]},{"cell_type":"markdown","metadata":{"id":"4WhMLsykdUEq"},"source":["### Exercise 4: An LSTM Character-based Language Model\n","\n","In this final exercise we will train a language model that will work at the character level. This is, a neural network based on an RNN architecture that will complete language (textual) sequences.\n"]},{"cell_type":"markdown","metadata":{"id":"KFGtDsWkUZoK"},"source":["Our dataset will be composed of scripts from the *Friends* TV show. Download the episode 1 trainset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTf9DUPreML-"},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/telecombcn-dl/labs-all/master/labs/rnn/episode1_english.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1669628616883,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"f64CyU0meML-","outputId":"8f0f8222-f707-455b-cb46-78232d6f2ec3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of found vocabulary tokens:  67\n"]}],"source":["# Let's prepare some synthetic data\n","\n","def prepare_sequence(seq, char2idx, onehot=True):\n","    # convert sequence of words to indices\n","    idxs = [char2idx[c] for c in seq]\n","    idxs = torch.tensor(idxs, dtype=torch.long)\n","    if onehot:\n","      # conver to onehot (if input to network)\n","      ohs = F.one_hot(idxs, len(char2idx)).float()\n","      return ohs\n","    else:\n","      return idxs\n","\n","with open('episode1_english.txt', 'r') as txt_f:\n","  training_data = [l.rstrip() for l in txt_f if l.rstrip() != '']\n","\n","# merge the training data into one big text line\n","training_data = '$'.join(training_data)\n","\n","# Assign a unique ID to each different character found in the training set\n","char2idx = {}\n","for sent in training_data:\n","    for c in sent:\n","        if c not in char2idx:\n","            char2idx[c] = len(char2idx)\n","idx2char = dict((v, k) for k, v in char2idx.items())\n","VOCAB_SIZE = len(char2idx)\n","RNN_SIZE = 1024\n","MLP_SIZE = 2048\n","SEQ_LEN = 50\n","print('Number of found vocabulary tokens: ', VOCAB_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"Ehk_6JNIkZOs"},"source":["##### Exercise 4.1\n","* What is the amount of outputs needed by the character prediction model?\n","el mismo que el de la entrada porque la predicci칩n se hace sobre cada caracter (por ejemplo usamos una softmax() para hacer la toma de decisi칩n en base a la probabilidad de cada caracter)\n","\n","##### Exercise 4.2\n","* What is the proper activation to plug on top of the MLP (if any)? (Note that we use `NLLLoss` later on).\n","Softmax() para obtener la probabilidad para cada caracter.\n","\n","##### Exercise 4.3\n","* Finish the definition of the `CharLSTM` model to include a `nn.LSTM` layer, with `batch_first=True`, `vocab_size` inputs and `rnn_size` cells, and an MLP that projects the `rnn_size` to `mlp_size` with one `ReLU` hidden layer and then to the appropriate amount of outputs. Put a `Dropout(0.4)` after the `ReLU`. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDCaSQFTeML_"},"outputs":[],"source":["class CharLSTM(nn.Module):\n","\n","    def __init__(self, vocab_size, rnn_size, mlp_size):\n","        super().__init__()\n","        self.rnn_size = rnn_size\n","\n","        # TODO: Define the LSTM\n","        self.lstm = nn.LSTM(vocab_size, rnn_size, batch_first=True)\n","\n","        self.dout = nn.Dropout(0.4)\n","\n","        # TODO: Create an MLP with a hidden layer of mlp_size neurons that maps\n","        # from the RNN hidden state space to the output space of vocab_size\n","        self.mlp = nn.Sequential(\n","          # Linear layer\n","          nn.Linear(rnn_size, mlp_size),\n","          # Activation function\n","          nn.ReLU(),\n","          # Dropout (0.4)\n","          nn.Dropout(0.4),\n","          # Linear layer\n","          nn.Linear(mlp_size, vocab_size),\n","          # Activation function\n","          nn.LogSoftmax()\n","        )\n","\n","    def forward(self, sentence, state=None):\n","        bsz, slen, vocab = sentence.shape\n","        ht, state = self.lstm(sentence, state)\n","        ht = self.dout(ht)\n","        h = ht.contiguous().view(-1, self.rnn_size)\n","        logprob = self.mlp(h)\n","        return logprob, state"]},{"cell_type":"markdown","metadata":{"id":"4K3L5BIyLrja"},"source":["Test how the model performs when using randomly initialized weights and biases:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669631501761,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"Hict7OnDeML_","outputId":"341db86c-10c0-4b21-dbbf-fcde0fc1ba58"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"]},{"name":"stdout","output_type":"stream","text":["Monica was .WW.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W.W\n"]}],"source":["# Let's build an example model and see what the scores are before training\n","model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n","\n","# This should output crap as it is not trained, so a fixed random tag for everything\n","\n","def gen_text(model, seed, char2idx, num_chars=150):\n","  model.eval()\n","  # Here we don't need to train, so the code is wrapped in torch.no_grad()\n","  with torch.no_grad():\n","      inputs = prepare_sequence(seed, char2idx)\n","      # fill the RNN memory with the seed sentence\n","      seed_pred, state = model(inputs.unsqueeze(0))\n","      # now begin looping with feedback char by char from the last prediction\n","      preds = seed\n","      curr_pred = torch.topk(seed_pred[-1, :], k=1, dim=0)[1]\n","      curr_pred = idx2char[curr_pred.item()]\n","      preds += curr_pred\n","      for t in range(num_chars):\n","        curr_pred, state = model(prepare_sequence(curr_pred, char2idx).unsqueeze(0), state)\n","        curr_pred = torch.topk(curr_pred[-1, :], k=1, dim=0)[1]\n","        curr_pred = idx2char[curr_pred.item()]\n","        if curr_pred == '$':\n","          # special token to add newline char\n","          preds += '\\n'\n","        else:\n","          preds += curr_pred\n","      return preds\n","\n","      \n","print(gen_text(model, 'Monica was ', char2idx))\n","#devuelve mierda porque la red no est치 entrenada"]},{"cell_type":"markdown","metadata":{"id":"a_HuhKqRL0p-"},"source":["Prepare the training data by defining the data batches:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1669631066076,"user":{"displayName":"Eduard Ramon Aliaga Torrens","userId":"14803091022029945885"},"user_tz":-60},"id":"O-kSNhXSeMMA","outputId":"f4aab9a1-898a-4413-ed20-176bb18cbc0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original training string len:  23149\n","Sub-sequences len:  361\n"]}],"source":["BATCH_SIZE = 64\n","T = len(training_data)\n","CHUNK_SIZE = T // BATCH_SIZE\n","# let's first chunk the huge train sequence into BATCH_SIZE sub-sequences\n","trainset = [training_data[beg_i:end_i] \\\n","            for beg_i, end_i in zip(range(0, T - CHUNK_SIZE, CHUNK_SIZE),\n","                                    range(CHUNK_SIZE, T, CHUNK_SIZE))]\n","print('Original training string len: ', T)\n","print('Sub-sequences len: ', CHUNK_SIZE)\n","\n","# The way training works is the following:\n","# at each batch sampling from the trainset, we pick a portion of sequences\n","# continuous with a sliding window in time. Hence, each of the BATCH_SIZE sub-sequences\n","# in batch b[i] will continue in batch b[i + 1] in the same position of the batch dimension.\n","# This is called stateful sampling, where we train with consecutive windows of sequences\n","# We broke the long string into BATCH_SIZE subsequence, so we introduced BATCH_SIZE - 1 \n","# discontinuities... YES. But we can assume that each sub-sequence is continuous in a long\n","# enough chunk so that those discontinuities are negligible."]},{"cell_type":"markdown","metadata":{"id":"NwjICWSN0wE4"},"source":[]},{"cell_type":"markdown","metadata":{"id":"0LXeQtq10v91"},"source":[]},{"cell_type":"markdown","metadata":{"id":"U_VVeGkjk5bs"},"source":["##### Exercise 4.4\n","\n","What is the length of the sliding window that will run over each of the training sub-sequences? \n","es el chunk size, se cogen los primeros 50 para entrenar y para la validaci칩n se cogen todos menos el primero\n","\n","NOTE: it is defined as a hyper-parameter above. How is this related to the backpropagation through time (BPTT)?\n","\n","Seria el seq_length"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"79ylaZabeMMB","outputId":"80070f15-99b6-42ec-ce74-6b295a9282bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------\n","They and I don't know the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore\n","------------------------------\n","Finished epoch 50 in 0.3 s: loss: 1.598674\n","------------------------------\n","They was now looking at me.\n","Monica: And you realizer you and Monica enters the a hing on the door and of Paul.\n","Chandler: Oh God, can I think you re sor a wo\n","------------------------------\n","Finished epoch 100 in 0.3 s: loss: 0.289253\n","------------------------------\n","They were'\n"," Loeding as Finiling pert had.)\n","Chandler: Please don't do that do thinks, in I suct here out of the gears. (This as nacked but wething a bean a p\n","------------------------------\n","Finished epoch 150 in 0.3 s: loss: 0.046510\n","------------------------------\n","They was no don't do and didn't know that he's a dead man.  Oh, Chandler? (Starts after thing a bitched there is. -What were you gonna say?\n","Paul: No, I'm te\n","------------------------------\n","Finished epoch 200 in 0.3 s: loss: 0.026306\n","------------------------------\n","They was no ding the parns to this as Chandler ast the toff and it.chat, I sain I can the work.\n","Chandler: Oh my God!\n","Paul: I know, I know, I'm such a mids a\n","------------------------------\n","Finished epoch 250 in 0.3 s: loss: 0.019805\n","------------------------------\n","They was on you th buck it his chene for the bertsome some out out of there, and I started wondering 'Why am I don't keow mo and I just who am I going out w\n","------------------------------\n","Finished epoch 300 in 0.3 s: loss: 0.017168\n","------------------------------\n","They were you found it. Oh bo. Alright. Goodnight, everybody.\n","Ross and Rachel: This is everybody, this is Paul.\n","All: Hey! Paul! Hi! The Wine Guy! Hey!\n","Chand\n","------------------------------\n","Finished epoch 350 in 0.3 s: loss: 0.012503\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it itll this fur. (They and sanele thate the can I there cluan fo\n","------------------------------\n","Finished epoch 400 in 0.3 s: loss: 0.011238\n","------------------------------\n","They wercon that me and Chandler are working at stab to the door.)... everybody, everybody, this is Paul.\n","Monica: Hi! Thank you to much!\n","Monica: Wat Ross: A\n","------------------------------\n","Finished epoch 450 in 0.3 s: loss: 0.009944\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, everybody, this is Rachel, another Lincol High survivor. (to Rachel) This is everybody, this is Rachel,\n","------------------------------\n","Finished epoch 500 in 0.3 s: loss: 0.012719\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, sore my a h!!\n","Whild I know what?  I think we can just leave it a that. You had you have it a shoed what\n","------------------------------\n","Finished epoch 550 in 0.3 s: loss: 0.009484\n","------------------------------\n","They were you found it. Oh bo. Dow you know how long it's been since I've grabbed a spoon? (Roes and dans at the and ressing the instructions) I'm suppose t\n","------------------------------\n","Finished epoch 600 in 0.3 s: loss: 0.011507\n","------------------------------\n","They were's only one flavor of ice cream for you. Little word guys. I have no back. (The sore there assembling furniture.]\n","Ross: I'm divorced!  I'm sursing \n","------------------------------\n","Finished epoch 650 in 0.3 s: loss: 0.008687\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it sool more...\n","Paul: I know.\n","(They a mean of sowe that?\n","Rachel: \n","------------------------------\n","Finished epoch 700 in 0.3 s: loss: 0.011288\n","------------------------------\n","They wern't looking at you before?!\n","Chandler: Okay, sit down. (Shows Paul in) Two a wasde!  Ohay don't days a little red.\n","Monica: (yelling from the dorr so \n","------------------------------\n","Finished epoch 750 in 0.3 s: loss: 0.008016\n","------------------------------\n","They ream Monica's geeky older hat mear. And than I found aromatherapy. So believe me, I, sumenter my ters.\n","[Scene: Monica's Apartment, Rachel is talking an\n","------------------------------\n","Finished epoch 800 in 0.3 s: loss: 0.007388\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it looking at him and and tay this guy was a libe hey, we's Burry\n","------------------------------\n","Finished epoch 850 in 0.3 s: loss: 0.009956\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, simesiture.]\n","Monica: (entering, to herself) Oh good, I'm stry... I am so sorry... I know you probably t\n","------------------------------\n","Finished epoch 900 in 0.3 s: loss: 0.006230\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, unless you gut what if I can't be gook.\n","(Monica goes to \n","------------------------------\n","Finished epoch 950 in 0.3 s: loss: 0.008760\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: So aly for the best, y'know? Independence. Taking contro of your life.  The whole, 'hat' thing.\n","Joey: (comort\n","------------------------------\n","Finished epoch 1000 in 0.3 s: loss: 0.006859\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, everybody, this is Rachel, another Lincol High survivor. (to Rachel) This is everybody, this is Rachel,\n","------------------------------\n","Finished epoch 1050 in 0.3 s: loss: 0.007589\n","------------------------------\n","They down't think. You re any how who was I just down tho got what if you gound out of beffine, and I realize there's a phone... there's only one flavor of \n","------------------------------\n","Finished epoch 1100 in 0.3 s: loss: 0.005274\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: 'Look, Gippetto youh really from the watch.\n","Monica: You and and that is goy are all bight?\n","Ross: No. I don't,\n","------------------------------\n","Finished epoch 1150 in 0.3 s: loss: 0.005016\n","------------------------------\n","They re a few. You're angry. You're hurting. Can I that's how we buy the love of a woman for four years.   Four yers. Morica's getting around the kitchen ta\n","------------------------------\n","Finished epoch 1200 in 0.3 s: loss: 0.004620\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, unless you much of you.\n","Monica: That's Paul's watch and \n","------------------------------\n","Finished epoch 1250 in 0.3 s: loss: 0.004774\n","------------------------------\n","They we come start was ataing it to be anywing s your of fou fee. (She starts massaging them.)\n","Monica: I just thought I was Monica's geeky olde grother.\n","Rac\n","------------------------------\n","Finished epoch 1300 in 0.3 s: loss: 0.004140\n","------------------------------\n","They wers going to ght do to this guy side that ever happened to you! You got married, you gotta unf again and she redials.)\n","[Scene: Ross's Apartment, they'\n","------------------------------\n","Finished epoch 1350 in 0.3 s: loss: 0.013260\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, simes what I was a lestare.\n","All: Okayy! (They do so.)\n","Chandler: Al right, kids, I gotta get to work. If\n","------------------------------\n","Finished epoch 1400 in 0.3 s: loss: 0.003383\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: And I just want a milliof Delcore hure, she pound the poons to the door.)... everybody, everybody, this is Pa\n","------------------------------\n","Finished epoch 1450 in 0.3 s: loss: 0.003508\n","------------------------------\n","They wern't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, wait, unless you just grabbed a spoon. (Roe any kind of a\n","------------------------------\n","Finished epoch 1500 in 0.3 s: loss: 0.013426\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, wait, unless you guys all have jobs?\n","Rachel: Hi, sure!\n","R\n","------------------------------\n","Finished epoch 1550 in 0.3 s: loss: 0.002891\n","------------------------------\n","They warn't to the door.)... everybody, everybody, this is Paul.\n","All: Hey! Paul! Hi! The Wine Guy! Hey!\n","Chandler: Look, Ross, you gotta und again and she re\n","------------------------------\n","Finished epoch 1600 in 0.3 s: loss: 0.003689\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, everybody, this is Rachel, another Lincol High survivor. (to Rachel) This is everybody, this is Rachel,\n","------------------------------\n","Finished epoch 1650 in 0.3 s: loss: 0.005551\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, wait, unless you wanna help?\n","Phoebe: (gring and reeping \n","------------------------------\n","Finished epoch 1700 in 0.3 s: loss: 0.004427\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I have kinda drifted apart, but out, and that's when it hit me: how much Barry loks like Mr. Potato Head. Y'k\n","------------------------------\n","Finished epoch 1750 in 0.3 s: loss: 0.004236\n","------------------------------\n","They were you found it. Oh bog.\n","Rachel: No. No, no, I'm not ready!  Hey, Paul!\n","Paul: Yeah?\n","Joey: Here's a little wow. Monica's table closer to the door so t\n","------------------------------\n","Finished epoch 1800 in 0.3 s: loss: 0.003356\n","------------------------------\n","They we can just leave it a woman for four years.   Four years.   Four years.   Four years.   Four years.   Four years.   Four years.   Four years.   Four y\n","------------------------------\n","Finished epoch 1850 in 0.3 s: loss: 0.003744\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, like, what, eight? Welcome back to the world 'f there, brought har the gigst citten whime.\n","Rachel: I'm \n","------------------------------\n","Finished epoch 1900 in 0.3 s: loss: 0.004398\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Al right, kids, I gotta get to work. If I don't input toget me, It's be the wand to ling o figure out what is\n","------------------------------\n","Finished epoch 1950 in 0.3 s: loss: 0.003301\n","------------------------------\n","They wern't looking at you before?!\n","Chandler: Okay, like, what, eight? Welcome back to the world was I sunding is the bookcase.)\n","Joey: I'm thinking we've ou\n","------------------------------\n","Finished epoch 2000 in 0.3 s: loss: 0.002532\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how we life down't this asazing? I mean, I have me a shoe? What if I wanna be a- a prang to tought I was \n","------------------------------\n","Finished epoch 2050 in 0.3 s: loss: 0.005502\n","------------------------------\n","They are al sined up livery warks to she dedn't do the wand waing the stairs!\n","(She starts massaging them.)\n","Monica: I just thought I was Monica's geeky olde \n","------------------------------\n","Finished epoch 2100 in 0.3 s: loss: 0.002442\n","------------------------------\n","They here's a dhone... there and I started wondering 'Why am I doing this, and who am I doing this for?'. (to Monica: You and To you grabbed a spoon. (Roe a\n","------------------------------\n","Finished epoch 2150 in 0.3 s: loss: 0.002743\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, everybody, this is Rachel, another Lincol High survivor. (to Rachel) This is everybody, this is Paul.\n","R\n","------------------------------\n","Finished epoch 2200 in 0.3 s: loss: 0.003574\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, und the kitchen table.\n","Rachel: Uh, credit card.\n","Monica: \n","------------------------------\n","Finished epoch 2250 in 0.3 s: loss: 0.002599\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: That's right.\n","Joey: Chandler the whit, ste shor and reachel: Thes is packing while Joey and Chandler are work\n","------------------------------\n","Finished epoch 2300 in 0.3 s: loss: 0.004829\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, unless my mother, which is very-very weird, but I don't \n","------------------------------\n","Finished epoch 2350 in 0.3 s: loss: 0.001682\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: And I just want a millio dollars! (He extends his hand hopefully.)\n","Monica: I know be all with Andrea--Angela-\n","------------------------------\n","Finished epoch 2400 in 0.3 s: loss: 0.002406\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: That's right.\n","Joey: What if you ge one woman- and that's it? Unfortunately in my cas, there was only one woma\n","------------------------------\n","Finished epoch 2450 in 0.3 s: loss: 0.002300\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it collapses.)\n","Ross: That only dogs and men with severe emotional\n","------------------------------\n","Finished epoch 2500 in 0.3 s: loss: 0.004832\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it does that mean?   Does he sell it, drink it, or a semp on y\n","------------------------------\n","Finished epoch 2550 in 0.3 s: loss: 0.001976\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it doe\n","note: Oh my God!\n","Paul: I know, I know, I'm such a mess \n","------------------------------\n","Finished epoch 2600 in 0.3 s: loss: 0.003819\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: So al walk with this albino guy who was, like, cleaning winds and realing the instructions) I'm supposed to a\n","------------------------------\n","Finished epoch 2650 in 0.3 s: loss: 0.003516\n","------------------------------\n","They wern't looking at you before?!\n","Chandler: And re a leftaver bair) Lome in you soup starting and Paul's watch and goes ato a hear?\n","Phoebe: All right, c'm\n","------------------------------\n","Finished epoch 2700 in 0.3 s: loss: 0.002476\n","------------------------------\n","They ream Monica's geeky olde brokked.\n","Chandler: Yes, please don't do that going it's a poone... there's nothing to tell! He's just some guys with a big ham\n","------------------------------\n","Finished epoch 2750 in 0.3 s: loss: 0.004012\n","------------------------------\n","They really not that hysterical phong... (Joey and Chandler are finishing sout her down the stairs!\n","(She starts my pauch and I don't want to be single, okay\n","------------------------------\n","Finished epoch 2800 in 0.3 s: loss: 0.003512\n","------------------------------\n","They we can I think whore gutt Joey like sime.\n","Rachel: That's right.\n","Joey: Chandler live of your love, ho work like you frolore you finnt it.)\n","Ross: C'mon, \n","------------------------------\n","Finished epoch 2850 in 0.3 s: loss: 0.001716\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it does that mean?   Does he sell it, drink it, or aplead on..\n","------------------------------\n","Finished epoch 2900 in 0.3 s: loss: 0.003421\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, this is a Dear Diary moment.\n","Monica: Rach, wait, und the would be too four your hove. You just put it bac\n","------------------------------\n","Finished epoch 2950 in 0.3 s: loss: 0.003072\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, God, sto go of my hair, my head will fall off.\n","Chandler: (reTV) Ooh, she should not be wearing those pant\n","------------------------------\n","Finished epoch 3000 in 0.3 s: loss: 0.002735\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it does me here, you can alays come to Joey. Me and Chandler l\n","------------------------------\n","Finished epoch 3050 in 0.3 s: loss: 0.002428\n","------------------------------\n","They here and wom ary acout that is and boes like umm, all my birthdays, both graduations, pus the barn raising scene in Witness.\n","Monica: We'll got is to be\n","------------------------------\n","Finished epoch 3100 in 0.3 s: loss: 0.002239\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this is.. (They are all lined up ne was ng snembing?\n","Ross: So Ross, Candler, and Phoebe, and\n","------------------------------\n","Finished epoch 3150 in 0.3 s: loss: 0.003284\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how wedding day!\n","Joey: What, like that? She didn't know, how should I know?\n","Chandler: I have kinda drifte\n","------------------------------\n","Finished epoch 3200 in 0.3 s: loss: 0.001962\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh God, can I You ready to jump and Monica turn to look at her.) bluebells and something wath mittens... La l\n","------------------------------\n","Finished epoch 3250 in 0.3 s: loss: 0.003343\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this is.. (They are all lined up ne watching a Spanish Soap on TV and are trying the befrred\n","------------------------------\n","Finished epoch 3300 in 0.3 s: loss: 0.001825\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I have kinda drifted apart, but out, and that's when it hit me: how much Barry loks like Mr. Potato Head. Y'k\n","------------------------------\n","Finished epoch 3350 in 0.3 s: loss: 0.002480\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this is.. (They are all lined up ne watching a Spanish Soap on TV and are trying to the door\n","------------------------------\n","Finished epoch 3400 in 0.3 s: loss: 0.003371\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it is.\n","(Monica You sout woman for everybody, y'know? I mean wh\n","------------------------------\n","Finished epoch 3450 in 0.3 s: loss: 0.003540\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Okay, sit down. (Shows Paul in) Twoseconds.\n","Phoebe: Ooh, I just pulled out four eyelahe.. That can't be good.\n","------------------------------\n","Finished epoch 3500 in 0.3 s: loss: 0.001270\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: 'me and wht kind a Spanish Soap on TV and are trying the gook Lenny and Squigy are here.\n","All: Morning. Good m\n","------------------------------\n","Finished epoch 3550 in 0.3 s: loss: 0.002970\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this is all about what I said the other day about it.\n","Chandler: (imitating the real Chandler\n","------------------------------\n","Finished epoch 3600 in 0.3 s: loss: 0.001541\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: 'Look, Gidpetto go, and I have kinda drifted apart, but out, and that's when it hit me: how much Barry loks l\n","------------------------------\n","Finished epoch 3650 in 0.3 s: loss: 0.002676\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I'm sorry, I didn't catch your name. Paul, was it does that mean?   Does he sell it, drink it, or a searting.\n","------------------------------\n","Finished epoch 3700 in 0.3 s: loss: 0.004045\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: I have kinda drifted apart, but out, and that's when it hit me: how much Barry loks like Mr. Potato Head. Y'k\n","------------------------------\n","Finished epoch 3750 in 0.3 s: loss: 0.002597\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Ploke, wo I'm back in high school, I'm standing in them! He's just some guys werking fros the door and it's P\n","------------------------------\n","Finished epoch 3800 in 0.3 s: loss: 0.002294\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Plok, wish me luck!\n","Monica: What for?\n","Rachel: I'm gonna be something wrong with him!\n","Chandler: All right Joey\n","------------------------------\n","Finished epoch 3850 in 0.3 s: loss: 0.001022\n","------------------------------\n","They was only one woman- for her...\n","Joey: What realize there's a phone... there is gonna be a fifth date?\n","Paul: Isn't there?\n","Monica: Yeah... you're having s\n","------------------------------\n","Finished epoch 3900 in 0.3 s: loss: 0.002113\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: 'Look, Gippettong that wish that out. (they of earcon that of and they are chell, this is Paul.\n","Rachel: Paul \n","------------------------------\n","Finished epoch 3950 in 0.3 s: loss: 0.002885\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: That's right.\n","Joey: Who's Paul?\n","Ross: Paul the Wine Guy?\n","Ross: You gry acreally, I don't want to.\n","Commecial B\n","------------------------------\n","Finished epoch 4000 in 0.3 s: loss: 0.002591\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it look my aula have bo the door sout that stop!  That was a libr\n","------------------------------\n","Finished epoch 4050 in 0.3 s: loss: 0.003064\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this for?'. (to Monica enters the living room as Ross is leaving.)\n","Monica: See ya.... Waitwa\n","------------------------------\n","Finished epoch 4100 in 0.3 s: loss: 0.001339\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how you don't feel like being along to the pard the citchen this is Piplers we've established who's stayi\n","------------------------------\n","Finished epoch 4150 in 0.3 s: loss: 0.001381\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how you don't fant to got think about him all day. Or else I'm just gonna get up and go to work.\n","Rachel: \n","------------------------------\n","Finished epoch 4200 in 0.3 s: loss: 0.001565\n","------------------------------\n","They was only one woman- for her...\n","Joey: What some you know Paul?\n","Frannie: Paul the Wine Guy? Oh yeah, I know Paul.\n","Monica: You mean you know Paul like thi\n","------------------------------\n","Finished epoch 4250 in 0.3 s: loss: 0.001215\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Look, Ross, you gotta unf again and she redials.)\n","[Scene: Ross's Apartment, they're all sitting there is. -Wh\n","------------------------------\n","Finished epoch 4300 in 0.3 s: loss: 0.001912\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this freban a lett me, there was no snap in his utting them up and they all cheer.)\n","Monica: \n","------------------------------\n","Finished epoch 4350 in 0.3 s: loss: 0.001804\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: It's a beautiful this for?'. (to Monica: So anyway I just didn't know where to go, and I know that you and I \n","------------------------------\n","Finished epoch 4400 in 0.3 s: loss: 0.001346\n","------------------------------\n","They here's like s figure you down't fave it him as Frannica: I think we are getting a little ahead of selve it, stipped and I said, 'What if I wanna be a- \n","------------------------------\n","Finished epoch 4450 in 0.3 s: loss: 0.002449\n","------------------------------\n","They here's like off and then you know Paul like thing ween of cour it?\n","Ross: I just feel like someone reached down the stairs!\n","(She starts my say fighthe y\n","------------------------------\n","Finished epoch 4500 in 0.3 s: loss: 0.001421\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and is looking for an 'Loes and Chandler are working as Frannica:\n","Mon\n","------------------------------\n","Finished epoch 4550 in 0.3 s: loss: 0.001684\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, had well walk like simethat my.\n","Chandler: St, please don't do that going to the dentist four and five tim\n","------------------------------\n","Finished epoch 4600 in 0.3 s: loss: 0.001886\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it looking for an answer more sow Paul?\n","Frannie: Are you kidding?\n","------------------------------\n","Finished epoch 4650 in 0.3 s: loss: 0.001053\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how well Paul did Chandler ght to the door.)... everybody, everybody, this is Paul.\n","Monica: Hi, I'm any d\n","------------------------------\n","Finished epoch 4700 in 0.3 s: loss: 0.000644\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Finally, I figure I'd better answer it, and it looking for an and watching a Spanish Soap on TV and are tryin\n","------------------------------\n","Finished epoch 4750 in 0.3 s: loss: 0.000699\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Oh, how sleave bout out of the wander.)\n","[Cut to Rachel starts looking at me.\n","Monica: You mean you know Paul l\n","------------------------------\n","Finished epoch 4800 in 0.3 s: loss: 0.002034\n","------------------------------\n","They were know, out, and that is why we don't do that down the stairs!\n","(She stops talking.]\n","Ross: (scornful) Grab a spoon!\n","Ross: I honestly don't know if I'\n","------------------------------\n","Finished epoch 4850 in 0.3 s: loss: 0.002960\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: And you never knew she was a lesbian... (They al stare at him.) Did I say that out loud?\n","Ross: I think ther u\n","------------------------------\n","Finished epoch 4900 in 0.3 s: loss: 0.001941\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: Stay out of my freezer!  And the through with a hair of scissors.]\n","Rachel: Oh God, can't that is and does it \n","------------------------------\n","Finished epoch 4950 in 0.3 s: loss: 0.001644\n","------------------------------\n","They weren't looking at you before?!\n","Chandler: And I just want a millio dollars! (He extends his hand hopefully.)\n","Monica: I know be heand I don't want to bu\n","------------------------------\n","Finished epoch 5000 in 0.3 s: loss: 0.001648\n"]},{"data":{"text/plain":["Text(0, 0.5, 'NLLLoss')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXkAAAEGCAYAAACAd+UpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYVUlEQVR4nO3deZQdZZnH8d/TS9JJukO2TgiE0ATCFlmnWUUYQSEEFEcdwUGHg5yDIio6KsvoMHjUQeWogHLAOGwCAyqIwyD7rgiEDiQhYcsCYUvSnT2drdPdz/xR1cntzu39Vlfdt7+fc/p03br3Vj1Vqfzy5q2qt8zdBQAIU0naBQAAkkPIA0DACHkACBghDwABI+QBIGBlaReQa9y4cV5TU5N2GQBQNGbPnr3S3as7ez9TIV9TU6O6urq0ywCAomFmS7t6n+4aAAgYIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACFkTIP/1mg95dvSntMgAgczJ1M1RfnXPTLJWWmBb/14y0SwGATAmiJS9JLa08/AQAOgom5AEAOyPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwABI+QBIGDBhHxVRRCPqwWAggoiGWvGDtfBk0alXQYAZE4QLXkzE4/xBoCdhRHyktyJeQDoKIiQl4mWPADkkXjIm1mpmb1sZvcntg6JlAeAPAaiJX+RpNeSXEHUJ0/KA0BHiYa8mU2SdJqk/050PZLokgeAnSXdkr9a0sWSWjv7gJmdb2Z1ZlbX0NDQp5WYEfIAkE9iIW9mp0uqd/fZXX3O3We6e62711ZXV/dtXaK7BgDySbIl/2FJnzSztyXdJelEM7s9iRXRkgeA/BILeXe/zN0nuXuNpLMkPeHuX0hsfUktGACKWBDXyZsZLXkAyGNAxq5x96ckPZXU8i2pBQNAkQuiJR+hKQ8AHQUR8px4BYD8wgn5tIsAgAwKI+RljEIJAHmEEfK05AEgrzBCXvTJA0A+QYS8eDIUAOQVRMjzZCgAyC+MkOduKADIK4yQF33yAJBPGCHPk6EAIK8wQl605AEgnzBCnmENACCvMEKeJ0MBQF5BhLxoyQNAXkGEvIlhDQAgnzBCnpQHgLzCCHmeDQUAeQUR8pI48QoAeQQR8lxCCQD5hRPyaRcBABkURsjzZCgAyCuMkKclDwB5laVdQCHMeXetNmxpTrsMAMicIFryBDwA5BdEyAMA8gsi5I/de2zaJQBAJgUR8nuOHaGqiiBOLwBAQQUR8n+Z94E2bGnmMkoA6CCIkJ/+oV0lSS2thDwA5Aoi5PccO0KS1EJLHgDaCSLky0qiUShpyQNAe0GEfGkc8s2EPAC0E1TIt7QQ8gCQK7GQN7MKM5tlZnPNbIGZ/SCpdZXRkgeAvJK8uHyrpBPdvdHMyiX9zcwedPfnC72i0pLo36pWTrwCQDuJhbxHF603xi/L459EUpiWPADkl2ifvJmVmtkcSfWSHnX3F/J85nwzqzOzuoaGhj6thz55AMgv0ZB39xZ3P1TSJElHmtmH8nxmprvXunttdXV1n9ZTVtrWkm/tT7kAEJwBubrG3ddKelLS9CSWX2JcJw8A+SR5dU21mY2Kp4dJ+rik15NYF33yAJBfklfXTJR0q5mVKvrH5A/ufn8SKyrljlcAyCvJq2vmSTosqeXnauuTJ+QBoL1A7niNNoMTrwDQXhAhv2OAspQLAYCMCSLkdwxQRsoDQK4gQn771TXcDAUA7QQR8lxdAwD59SjkzewiMxtpkRvN7CUzOznp4nqqvLTtxCshDwC5etqS/5K7r5d0sqTRkr4o6SeJVdVLO1ry9MkDQK6ehrzFv2dIus3dF+TMSx13vAJAfj0N+dlm9oiikH/YzKokZabZTJ88AOTX0ztez5N0qKQl7r7JzMZIOje5snqnLL4ZahtX1wBAOz1tyR8j6Q13X2tmX5D0fUnrkiurd7YPNczdUADQTk9D/npJm8zsEEnflrRY0u8Sq6qX2kJ+G901ANBOT0O+OX6c3xmSfu3u10mqSq6s3ilvG7uGljwAtNPTPvkNZnaZoksnP2JmJYqe2ZoJ5WVtIU9LHgBy9bQlf6akrYqul1+u6HF+VyVWVS+1XUK5fsu2lCsBgGzpUcjHwX6HpF3M7HRJW9w9M33ybXe8/uqJRSlXAgDZ0tNhDT4naZakf5b0OUkvmNlnkyysN9quk7fM3J4FANnQ0z7570k6wt3rpej5rZIek3R3UoX1hdMlDwDt9LRPvqQt4GOrevFdAEBKetqSf8jMHpZ0Z/z6TEkPJlNS300eMzztEgAgU3oU8u7+XTP7tKTj4lkz3f3e5Mrqvf13rSLkAaCDnrbk5e5/kvSnttdm9o67T06kqj4YUlaiJm6GAoB2+tOvnqlrWYaUlqipmZAHgFz9CflMXcsypIyQB4COuuyuMbN/6+wtSZWFL6fvhpSVqHFrc9plAECmdNcn39UgZNcUspD+envlRr29alPaZQBApnQZ8u7+g87eM7NvFr6cviPgAWBn/emT76wrBwCQEcFcXQMA2FkwV9e0eYduGwDYrrurazYof5ibpEzeXvrmig2aPDaTpQHAgOvuxGtmHvHXU2Mqh6RdAgBkRp+7a8zsnUIWUih/W7gy7RIAIDMSO/FqZnuY2ZNm9qqZLTCzi/qxrh67/qnFA7EaACgKSZ54bZb0bXc/UNLRki40swP7sb4uTakeIUkaPqQ0qVUAQNFJbFgDd18maVk8vcHMXpO0u6RX+1Bnt95auVGStGpjUxKLB4Ci1F1LvqqTn0r1YlgDM6uRdJikF/K8d76Z1ZlZXUNDQ08XuZOzj8rMqMcAkBl9Htagp8ysUtI9kr7p7uvzrGOmpJmSVFtb2+dr7//psEm6/flMngsGgNR0111zeRdvu7v/sJvvlysK+Dvih44kprpyaJKLB4Ci1N0olBvzzBsh6TxJYyV1GvJmZpJulPSau/+izxX2EDdAAcDOuuuu+XnbtJlVSbpI0rmS7pL0886+F/uwpC9KesXM5sTz/t3dH+h7uQCA3uj2Ga9mNkbRiJNnS7pV0uHuvqa777n738QgZgCQqu765K+S9GlFJ0YPcvfGAakKAFAQ3V1C+W1Ju0n6vqQPzGx9/LPBzHa6UgYAkC3d9cn3547Y1Li7ovO+ADC4FWWId+f15RvSLgEAMiHIkH+DkAcASYGG/Ir1W9IuAQAyIaiQryiPNmdbS2vKlQBANgQV8hf+4z6SpKfe6PtAZwAQkqBCftO2FklS3dJu79UCgEEhqJCfOr7LIe4BYNAJKuRPP3i3tEsAgEwJKuSHlAW1OQDQb6QiAASMkAeAgBHyABAwQh4AAkbIA0DAggv54/etliS1tHrKlQBA+oIL+ffXbJIkvRf/BoDBLLiQX9ywUZJ09WMLU64EANIXXMi3GT18SNolAEDqggv58tLosX83PftWypUAQPqCC/mp46vSLgEAMiO4kD9kj1FplwAAmRFcyF9wwt5plwAAmRFcyI+r4oQrALQJLuQrykrTLgEAMiO4kC8psbRLAIDMCC7kAQA7EPIAEDBCHgACRsgDQMAIeQAIWGIhb2Y3mVm9mc1Pah0AgK4l2ZK/RdL0BJffqUmjh6WxWgDInMRC3t2fkbQ6qeV35b01myVJqzc2pbF6AMiMoPvk3XkEIIDBLfWQN7PzzazOzOoaGhoKuux1m7cVdHkAUGxSD3l3n+nute5eW11dXdBlv7VyY0GXBwDFJvWQT8Kxe4+VJI2tHJpyJQCQriQvobxT0nOS9jOz98zsvKTW1dG/HrOnJImxygAMdkleXfN5d5/o7uXuPsndb0xqXR09vGCFJOnaxxcO1CoBIJOC7K7ZsKVZkvT+2i0pVwIA6Qoy5HcZVi5JWr5uc8qVAEC6ggz5U6ZNkCSN48QrgEEuyJA/akp0dc2pB01MuRIASFeQIV9eGl1Ww4lXAINdkCFfVhLkZgFArwWZhm0teQAY7IIMeTNCHgCkQEMeABAh5AEgYIQ8AASMkAeAgAUb8vvvWpV2CQCQurK0C0jKoXuM0iqe8QpgkAu2JV9eWqKGDVvTLgMAUhVsyN/2/FJJUv16hhsGMHgFG/Jt6LIBMJgFH/Lvrt6UdgkAkJpgQ/77px0gSRoZP0AEAAajYEN+6aqoBX/5/85PuRIASE+wId82RtmK9VxhA2DwCjbkj9xrjCRpP26KAjCIBRvyNWNHSJJWcAklgEEs2JDfu7pS0o6+eQAYjIIN+YryYDcNAHos2CTk6VAAEHDIAwAGSci3tHraJQBAKgZFyD+7aGXaJQBAKoIO+VHDoyENlq3bnHIlAJCOoEP+yJrohqhL7nkl5UoAIB1Bh/x/fnJa2iUAQKqCDvndRw3bPn3lg6+lWAkApCPokM/1m6eX6Bt3vpx2GQAwoBINeTObbmZvmNkiM7s0yXV1Zu7lJ2+fvm/uB6q59C+qufQv+spts/XD+19Vc0urWgO7xHLpqo3bp9dv2abNTS09+t5vn1miF5as6vT9puZWHfHjx3TP7Pf6XWMhbG1uUVNza6+/t27zNi2qb0ygosJw79nxuGzd5oIdu9c8tlAvvbOmIMsqZttaWnX/vA96/GdQDCypjTGzUklvSvq4pPckvSjp8+7+amffqa2t9bq6uoLX8n9zP9DXB3krfvKY4Zq220g9tGC5Rg8fotXdPBbxlGkTdMK+4zVqeLkatzbr4rvntXv/opOm6lOH7a5l6zZr9ttr9OQb9Tpx//G6c9a7mlI9Qn9duFJ7jBmmd1dHVzYNKy9VWYnpyydM0egRQ9Tq0VO7avccrQfnL9e9L7+/fdmHTx6ll95ZK0k6//gpmrhLhQ6bPFqVQ8v0kwdf12OvrWhXyzPf/aiqKsr0yKvL9eeXP9BzS1ZpxkG76oFXluvi6fvpidfqZSZVlJfq7KP21Fduny1J+vLxU/SJQ3bTbc8tVWNTs46ZMlYjh5Vrn+pKPbtopWYvXaM36zdoScNGVVWU6bSDJqqpuVUNjVv114UrdfZRk/XR/cbr4Em76InX6zXzmSX69b8crvvmfqB9J1TqP/48X984aaqufPB1SdIXjp6sLdtaVWLRg+aPnjJWJWZ6cP4ynX7wRO0ybIi+9j8vadXGJo2sKNN3TtlP03Ybqc9c/5wk6YR9q1Vi0rF7j1NTS6uuevgNfeyACbrwo3urrKRElRVlGjWsXDc/+5ZO2K9aixs26pEFK3TAxCqNqxyqE/cfrxFDy/TLR9/U1AmV2mvcCH3xxlm66KSpuubxhZKk5y87Sas3Nqlxa7OGDynVl255UUdNGaum5hbtM75S5aUluvqxhTr5wAnad0KVzjtuL81eukYvLl2tFeu26BOH7KbKoWVasWGrqirKdO7NL+rKTx+k0w6eqLIS09x312lxQ6N2HzVMe1dX6qk36/Wbp5do5LByXXPWoWpqbtXIinItWdmoI2rGaOYzS7SooVE//czBuuGpxVrc0KhLpu+vXzz6ps45dk9N220X3fD0Yj3xer2u+OQ0DSmN2q0jK8pVWmpqam7V+KqhWrt5m55fvEot7jpo9+g7H5lare/8ca52HVmhy2bsr9IS07OLVunOWe/oI1PH6bzj9tJ1Ty7SB2u36OLp+8ldOmKvMXpg3jLtM6FSe40doTGVQ1Q1tEwtra7Grc16b83m7SPfPvDKMj35er1Wb9qmb31sqoaWlWrFhi2aOr5Sazdt0wETR6phw1YdfeXj+vLxU3TZjAN6/xdbkpnNdvfaTt9PMOSPkXSFu58Sv75Mktz9ys6+k1TItzngPx7S5m09a9UCwEBa9ONTVVba+86V7kK+rF9VdW13Se/mvH5P0lEdP2Rm50s6X5ImT56cYDnSaz+c3u51S6trUX2jyktNc95dq7dWbtSaTU26/fl3Eq0DADpKqtc4yZDvEXefKWmmFLXkB3LdpSW2/b9WU+KhiSXpR586aCDLAIDEJHni9X1Je+S8nhTPAwAMkCRD/kVJU81sLzMbIuksSfcluD4AQAeJdde4e7OZfU3Sw5JKJd3k7guSWh8AYGeJ9sm7+wOSHkhyHQCAzg2aO14BYDAi5AEgYIQ8AASMkAeAgCU2rEFfmFmDpKV9/Po4ScXynL9iqlUqrnqLqVapuOotplql4qq3P7Xu6e7Vnb2ZqZDvDzOr62r8hiwpplql4qq3mGqViqveYqpVKq56k6yV7hoACBghDwABCynkZ6ZdQC8UU61ScdVbTLVKxVVvMdUqFVe9idUaTJ88AGBnIbXkAQAdEPIAELCiD/ksPCw8p5a3zewVM5tjZnXxvDFm9qiZLYx/j47nm5ldG9c9z8wOz1nOOfHnF5rZOQWq7SYzqzez+TnzClabmf1DvO2L4u9aAvVeYWbvx/t3jpnNyHnvsnjdb5jZKTnz8x4f8RDYL8Tzfx8Ph93XWvcwsyfN7FUzW2BmF8XzM7d/u6g1q/u2wsxmmdncuN4fdLUOMxsav14Uv1/T1+0oYK23mNlbOfv20Hj+wBwH7l60P4qGMF4saYqkIZLmSjowxXreljSuw7yfSbo0nr5U0k/j6RmSHpRkko6W9EI8f4ykJfHv0fH06ALUdrykwyXNT6I2SbPiz1r83VMTqPcKSd/J89kD4z/7oZL2io+J0q6OD0l/kHRWPH2DpAv6UetESYfH01WKHmB/YBb3bxe1ZnXfmqTKeLpc0gvxfsi7DklflXRDPH2WpN/3dTsKWOstkj6b5/MDchwUe0v+SEmL3H2JuzdJukvSGSnX1NEZkm6Np2+V9Kmc+b/zyPOSRpnZREmnSHrU3Ve7+xpJj0qa3nGhveXuz0hanURt8Xsj3f15j47E3+Usq5D1duYMSXe5+1Z3f0vSIkXHRt7jI279nCjp7jzb3pdal7n7S/H0BkmvKXrGceb2bxe1dibtfevu3hi/LI9/vIt15O7zuyWdFNfUq+0ocK2dGZDjoNhDPt/Dwrs6YJPmkh4xs9kWPaBckia4+7J4ermkCfF0Z7UP5DYVqrbd4+mO85Pwtfi/tje1dX/0od6xkta6e3Oh6427Bw5T1IrL9P7tUKuU0X1rZqVmNkdSvaLAW9zFOrbXFb+/Lq5pQP6+dazV3dv27Y/jfftLMxvasdYe1tSn46DYQz5rjnP3wyWdKulCMzs+9834X99MXrOa5dpyXC9pb0mHSlom6efpltOemVVKukfSN919fe57Wdu/eWrN7L519xZ3P1TRc6KPlLR/yiV1qmOtZvYhSZcpqvkIRV0wlwxkTcUe8pl6WLi7vx//rpd0r6IDckX83yzFv+vjj3dW+0BuU6Fqez+eTrRmd18R/yVqlfRbRfu3L/WuUvRf47IO8/vMzMoVheYd7v6neHYm92++WrO8b9u4+1pJT0o6pot1bK8rfn+XuKYB/fuWU+v0uIvM3X2rpJvV933bt+Ogu077LP8oenzhEkUnUtpOmkxLqZYRkqpypv+uqC/9KrU/+fazePo0tT/pMst3nHR5S9EJl9Hx9JgC1Vij9icyC1abdj4hNCOBeifmTH9LUR+rJE1T+5NqSxSdUOv0+JD0R7U/cffVftRpivpHr+4wP3P7t4tas7pvqyWNiqeHSfqrpNM7W4ekC9X+xOsf+rodBax1Ys6+v1rSTwbyOBjwMCz0j6Iz1G8q6qf7Xop1TIkPkLmSFrTVoqg/8HFJCyU9lvOHZZKui+t+RVJtzrK+pOjE0CJJ5xaovjsV/Td8m6K+vPMKWZukWknz4+/8WvHd1AWu97a4nnmS7lP7YPpevO43lHPFQWfHR/znNSvejj9KGtqPWo9T1BUzT9Kc+GdGFvdvF7Vmdd8eLOnluK75ki7vah2SKuLXi+L3p/R1OwpY6xPxvp0v6XbtuAJnQI4DhjUAgIAVe588AKALhDwABIyQB4CAEfIAEDBCHgACRshjUDGzlpzRAOf0Z9TBPMuusZxRM4EsKOv+I0BQNnt02zkwKNCSB7T9WQA/i8fqnmVm+8Tza8zsiXhwqcfNbHI8f4KZ3RuPHT7XzI6NF1VqZr+NxxN/xMyGpbZRgAh5DD7DOnTXnJnz3jp3P0jRnYRXx/N+JelWdz9Y0h2Sro3nXyvpaXc/RNG49wvi+VMlXefu0yStlfSZhLcH6BJ3vGJQMbNGd6/MM/9tSSe6+5J4AK/l7j7WzFYqusV/Wzx/mbuPM7MGSZM8GnSqbRk1ioaXnRq/vkRSubv/KPktA/KjJQ/s4J1M98bWnOkWcd4LKSPkgR3OzPn9XDz9d0WjGUrS2YpGFpSigccukLY/KGKXgSoS6A1aGRhshsVP7mnzkLu3XUY52szmKWqNfz6e93VJN5vZdyU1SDo3nn+RpJlmdp6iFvsFikbNBDKFPnlA2/vka919Zdq1AIVEdw0ABIyWPAAEjJY8AASMkAeAgBHyABAwQh4AAkbIA0DA/h+OseEEJSk2dgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Let's now build a model to train with its optimizer and loss\n","model = CharLSTM(VOCAB_SIZE, RNN_SIZE, MLP_SIZE)\n","model.to(device)\n","loss_function = nn.NLLLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","NUM_EPOCHS = 5000\n","tr_loss = []\n","state = None\n","timer_beg = timer()\n","for epoch in range(NUM_EPOCHS):\n","  model.train()\n","  # let's slide over our dataset\n","  for beg_t, end_t in zip(range(0, CHUNK_SIZE - SEQ_LEN - 1, SEQ_LEN + 1),\n","                          range(SEQ_LEN + 1, CHUNK_SIZE, SEQ_LEN + 1)):\n","    # Step 1. Remember that Pytorch accumulates gradients.\n","    # We need to clear them out before each instance\n","    optimizer.zero_grad()\n","\n","    dataX = []\n","    dataY = []\n","    # Step 2. Get our inputs ready for the network, that is, turn them into\n","    # Tensors of one-hot sequences. \n","    for sent in trainset:\n","      # chunk the sentence\n","      chunk = sent[beg_t:end_t]\n","      # get X and Y with a shift of 1\n","      X = chunk[:-1]\n","      Y = chunk[1:]\n","      # convert each sequence to one-hots and labels respectively\n","      X = prepare_sequence(X, char2idx)\n","      Y = prepare_sequence(Y, char2idx, onehot=False)\n","      dataX.append(X.unsqueeze(0)) # create batch-dim\n","      dataY.append(Y.unsqueeze(0)) # create batch-dim\n","    dataX = torch.cat(dataX, dim=0).to(device)\n","    dataY = torch.cat(dataY, dim=0).to(device)\n","\n","    # Step 3. Run our forward pass.\n","    # Forward through model and carry the previous state forward in time (statefulness)\n","    y_, state = model(dataX, state)\n","    # detach the previous state graph to not backprop gradients further than the BPTT span\n","    state = (state[0].detach(), # detach c[t]\n","             state[1].detach()) # detach h[t]\n","\n","    # Step 4. Compute the loss, gradients, and update the parameters by\n","    #  calling optimizer.step()\n","    loss = loss_function(y_, dataY.view(-1))\n","    loss.backward()\n","    optimizer.step()\n","    tr_loss.append(loss.item())\n","  timer_end = timer()  \n","  if (epoch + 1) % 50 == 0:\n","    # Generate a seed sentence to play around\n","    model.to('cpu')\n","    print('-' * 30) \n","    print(gen_text(model, 'They ', char2idx))\n","    print('-' * 30)\n","    model.to(device)\n","    print('Finished epoch {} in {:.1f} s: loss: {:.6f}'.format(epoch + 1, \n","                                                               timer_end - timer_beg,\n","                                                               np.mean(tr_loss[-10:])))\n","  timer_beg = timer()\n","\n","plt.plot(tr_loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('NLLLoss')"]},{"cell_type":"markdown","metadata":{"id":"Iulcm9gPNhwK"},"source":["Now that the generator of characters is trained, we can ask it to predict the rest of a sentence that begins with `Professor `:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMLeaEfUeMMB"},"outputs":[],"source":["print(gen_text(model.to('cpu'), 'Professor ', char2idx, 1000))"]},{"cell_type":"markdown","metadata":{"id":"lVRsFgHZa3f3"},"source":["### References\n","\n","[1] https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/telecombcn-dl/labs-all/blob/main/labs/rnn/lab_rnn_todo.ipynb","timestamp":1669626124010}]},"kernelspec":{"display_name":"Python 3.7.10 ('trading')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.10"},"vscode":{"interpreter":{"hash":"148c72a8fa8931f1b4adec61e5c626da15d84fdba20a1a50eaf0317d3b0337d5"}}},"nbformat":4,"nbformat_minor":0}